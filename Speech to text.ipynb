{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech to Text gENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "# Load the Whisper model\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "# Function to record audio and save as WAV file\n",
    "def record_audio(duration=5, sample_rate=44100):\n",
    "    print(\"üé§ Recording... Speak now!\")\n",
    "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype=np.int16)\n",
    "    sd.wait()\n",
    "    wav.write(\"input_audio.wav\", sample_rate, audio)\n",
    "    print(\"‚úÖ Recording complete!\")\n",
    "\n",
    "# Function to transcribe the recorded audio\n",
    "def transcribe_audio():\n",
    "    result = whisper_model.transcribe(\"input_audio.wav\")\n",
    "    return result[\"text\"].lower()\n",
    "\n",
    "# Record and transcribe\n",
    "record_audio()\n",
    "text_command = transcribe_audio()\n",
    "print(f\"üó£Ô∏è Recognized Speech: {text_command}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 Classes\n",
    "cifar10_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n",
    "                   \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "# Function to find the closest CIFAR-10 class\n",
    "def map_to_cifar10(text_command):\n",
    "    for cls in cifar10_classes:\n",
    "        if cls in text_command:\n",
    "            return cifar10_classes.index(cls), cls  # Return index & class name\n",
    "    return None, None  # No match found\n",
    "\n",
    "# Find the corresponding CIFAR-10 class\n",
    "label_index, label_name = map_to_cifar10(text_command)\n",
    "\n",
    "if label_name:\n",
    "    print(f\"üéØ Mapped Class: {label_name} ({label_index})\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid CIFAR-10 class detected!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.utils as vutils\n",
    "\n",
    "# Function to generate an image based on speech input\n",
    "def generate_from_voice(generator, label_index, label_name):\n",
    "    generator.eval()  # Set to evaluation mode\n",
    "    \n",
    "    # Generate random noise\n",
    "    noise = get_random_noise(1, noise_dim)\n",
    "    \n",
    "    # Convert label to tensor\n",
    "    label = torch.tensor([label_index]).to(device)\n",
    "\n",
    "    # Generate the image\n",
    "    with torch.no_grad():\n",
    "        fake_img = generator(noise, label)\n",
    "    \n",
    "    # Unnormalize and display the image\n",
    "    fake_img = (fake_img + 1) / 2  # Scale from [-1,1] to [0,1]\n",
    "    \n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(np.transpose(fake_img[0].cpu().numpy(), (1, 2, 0)))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Generated Image: {label_name}\")\n",
    "    plt.show()\n",
    "\n",
    "# Generate image if a valid label was detected\n",
    "if label_name:\n",
    "    generate_from_voice(generator, label_index, label_name)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid image can be generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
